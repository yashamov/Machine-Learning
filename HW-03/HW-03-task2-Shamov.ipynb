{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "54064e54",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "67c45b57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Генерируем случайные данные\n",
    "X, y = make_regression(n_samples=100, n_features=5, noise=0.1, random_state=42)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceec9118",
   "metadata": {},
   "source": [
    "### Дерево"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7cca8955",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Дерево из первой домашки\n",
    "\n",
    "class MyDecisionTree:\n",
    "    def __init__(self, max_depth=None, min_samples_leaf=1):\n",
    "        self.max_depth = max_depth\n",
    "        self.min_samples_leaf = min_samples_leaf\n",
    "        self.tree = None\n",
    "\n",
    "    def gini(self, y):\n",
    "        classes, counts = np.unique(y, return_counts=True)\n",
    "        probabilities = counts / len(y)\n",
    "        gini_impurity = 1 - np.sum(probabilities ** 2)\n",
    "        return gini_impurity\n",
    "\n",
    "    def split(self, X, y, feature_index, threshold):\n",
    "        mask = X[:, feature_index] <= threshold\n",
    "        return X[mask], y[mask], X[~mask], y[~mask]\n",
    "\n",
    "    def find_best_split(self, X, y):\n",
    "        m, n = X.shape\n",
    "        if m <= 1:\n",
    "            return None, None\n",
    "\n",
    "        current_gini = self.gini(y)\n",
    "        best_gini = 1\n",
    "        best_feature = None\n",
    "        best_threshold = None\n",
    "\n",
    "        for feature_index in range(n):\n",
    "            thresholds = np.unique(X[:, feature_index])\n",
    "            for threshold in thresholds:\n",
    "                X_left, y_left, X_right, y_right = self.split(X, y, feature_index, threshold)\n",
    "\n",
    "                if len(y_left) < self.min_samples_leaf or len(y_right) < self.min_samples_leaf:\n",
    "                    continue\n",
    "\n",
    "                gini_left = self.gini(y_left)\n",
    "                gini_right = self.gini(y_right)\n",
    "\n",
    "                weighted_gini = (len(y_left) / m) * gini_left + (len(y_right) / m) * gini_right\n",
    "\n",
    "                if weighted_gini < best_gini:\n",
    "                    best_gini = weighted_gini\n",
    "                    best_feature = feature_index\n",
    "                    best_threshold = threshold\n",
    "\n",
    "        return best_feature, best_threshold\n",
    "\n",
    "    def build_tree(self, X, y, depth):\n",
    "        if depth == 0 or len(np.unique(y)) == 1:\n",
    "            return np.mean(y)\n",
    "\n",
    "        best_feature, best_threshold = self.find_best_split(X, y)\n",
    "\n",
    "        if best_feature is None:\n",
    "            return np.mean(y)\n",
    "\n",
    "        X_left, y_left, X_right, y_right = self.split(X, y, best_feature, best_threshold)\n",
    "\n",
    "        left_subtree = self.build_tree(X_left, y_left, depth - 1)\n",
    "        right_subtree = self.build_tree(X_right, y_right, depth - 1)\n",
    "\n",
    "        return (best_feature, best_threshold, left_subtree, right_subtree)\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.tree = self.build_tree(X, y.astype(int), self.max_depth)\n",
    "\n",
    "    def predict_instance(self, x, node):\n",
    "        if np.isscalar(node):\n",
    "            return node  # leaf node\n",
    "\n",
    "        feature, threshold, left_subtree, right_subtree = node\n",
    "        if x[feature] <= threshold:\n",
    "            return self.predict_instance(x, left_subtree)\n",
    "        else:\n",
    "            return self.predict_instance(x, right_subtree)\n",
    "\n",
    "    def predict(self, X):\n",
    "        return np.array([self.predict_instance(x, self.tree) for x in X])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2785b0d1",
   "metadata": {},
   "source": [
    "### Градиентный бустинг"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "56155efc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyGradientBoosting:\n",
    "    def __init__(self, n_estimators=100, learning_rate=0.1, max_depth=None, min_samples_leaf=1):\n",
    "        self.n_estimators = n_estimators\n",
    "        self.learning_rate = learning_rate\n",
    "        self.max_depth = max_depth\n",
    "        self.min_samples_leaf = min_samples_leaf\n",
    "        self.trees = []\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        predictions = np.zeros_like(y, dtype=np.float64)\n",
    "\n",
    "        for _ in range(self.n_estimators):\n",
    "            residuals = y - predictions\n",
    "            \n",
    "            tree = MyDecisionTree(max_depth=self.max_depth, min_samples_leaf=self.min_samples_leaf)\n",
    "            tree.fit(X, residuals)\n",
    "            \n",
    "            tree_pred = tree.predict(X)\n",
    "            predictions += self.learning_rate * tree_pred\n",
    "\n",
    "            self.trees.append(tree)\n",
    "\n",
    "    def predict(self, X):\n",
    "        predictions = np.zeros(len(X))\n",
    "\n",
    "        for tree in self.trees:\n",
    "            tree_pred = tree.predict(X)\n",
    "            predictions += self.learning_rate * tree_pred\n",
    "\n",
    "        return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bd576cbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Обучаем градиентный бустинг\n",
    "gb = MyGradientBoosting(n_estimators=100, learning_rate=0.1, max_depth=3, min_samples_leaf=5)\n",
    "gb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "db6d75e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Предиктим\n",
    "y_pred = gb.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ab729993",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 2282.4360685281927\n",
      "R^2 Score: 0.8863451236457112\n",
      "Mean Absolute Error: 33.883434156300666\n"
     ]
    }
   ],
   "source": [
    "# Оцениваем качество модели\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "print(f\"Mean Squared Error: {mse}\")\n",
    "print(f\"R^2 Score: {r2}\")\n",
    "print(f\"Mean Absolute Error: {mae}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "134bbe14",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dc15b2c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b51e14b0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
